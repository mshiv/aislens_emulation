{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac3d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ease of use, the mpas-analysis conda environment can be installed, \n",
    "# which includes most of the following packages.\n",
    "\n",
    "# xeofs, rioxarray will be required as additional packages.\n",
    "# cmocean colormaps may be required, if plotting the EOF mode figures.\n",
    "\n",
    "import sys\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import gc\n",
    "import collections\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams, cycler\n",
    "from matplotlib import animation, rc\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from xeofs.xarray import EOF\n",
    "import rioxarray\n",
    "\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from shapely.geometry import mapping\n",
    "from xarrayutils.utils import linear_trend, xr_linregress\n",
    "import pandas as pd\n",
    "#import cmocean\n",
    "\n",
    "# NOTE:\n",
    "# This version of the code uses a modified version of the xeofs package which can be downloaded here:\n",
    "# https://github.com/mshiv/xeofs-rand\n",
    "# Future versions with refactored codebase can be found at https://github.com/mshiv/aislens_emulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cbe269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To update following with relative repository paths once data and code is up on Zenodo\n",
    "# Current version uses the project template on Github.\n",
    "\n",
    "# Define project repo path\n",
    "inDirName = '/main_directory_path/'\n",
    "\n",
    "# DATA FILE PATHS\n",
    "# Data containing regridded flux and SSH for 150 years\n",
    "# The input dataset is a 3 dimensional NETCDF file with ('time','y','x') dimensions.\n",
    "# 'y','x' are used here as the data is gridded in polar stereographic coordinates.\n",
    "\n",
    "# The variable resolution dataset used in this study can be downloaded from\n",
    "# https://esgf-node.llnl.gov/search/e3sm/ (for V1 Cryosphere Campaign)\n",
    "# The current workflow in this notebook is set up for a constant resolution grid in space and time, \n",
    "# so the MPAS-Ocean dataset should be regridded. These steps are provided in separate Python scripts,\n",
    "# which assume the user has access to MPAS-Ocean output.\n",
    "\n",
    "regriddedFluxSSH_filepath = 'RegriddedFluxSSH.nc'\n",
    "regridded_data = xr.open_dataset(inDirName+regriddedFluxSSH_filepath)\n",
    "flux = regridded_data.timeMonthly_avg_landIceFreshwaterFlux\n",
    "ssh = regridded_data.timeMonthly_avg_ssh\n",
    "\n",
    "# Ice shelf boundary definitions: https://github.com/MPAS-Dev/geometric_features\n",
    "iceShelvesShape_filepath = 'iceShelves.geojson'\n",
    "\n",
    "# \"Dedrafted \"\n",
    "iceshelves_dedrafted_total = xr.open_dataset('iceshelves_dedrafted_total.nc')\n",
    "flux_dedraft = iceshelves_dedrafted_total.timeMonthly_avg_landIceFreshwaterFlux\n",
    "\n",
    "# Demean: remove temporal mean\n",
    "flux_dedraft_tmean = flux_dedraft.mean('time')\n",
    "flux_dedraft_demeaned = flux_dedraft - flux_dedraft_tmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d4f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original forcing data: raw MPAS-O output, mapped to the 10km resolution grid\n",
    "# flux is freshwater flux\n",
    "# ssh is sea surface height, used here as a proxy for ice draft / depth.\n",
    "\n",
    "# ssh is used to plot the scatterplot of flux vs. draft for different ice shelves \n",
    "# and as input for the linear regression used in \"dedrafting\" the dataset\n",
    "\n",
    "sec_per_year = 365*24*60*60\n",
    "rho_fw = 1000\n",
    "\n",
    "# Pre-processed data: detrended, deseasonalized, dedrafted\n",
    "flux_clean = xr.open_dataset(inDirName+'flux_clean')\n",
    "flux_clean = flux_clean.timeMonthly_avg_landIceFreshwaterFlux\n",
    "\n",
    "# Flux datapoints extracted for individual ice shelves, used for the scatter plots\n",
    "catchments_scatter = np.load(inDirName+interim_data_folder+\"catchments_scatter.npy\")\n",
    "catchments_scatter_xr = xr.DataArray(catchments_scatter,dims={'basin','x','y'})\n",
    "catchments_scatter = catchments_scatter*sec_per_year/rho_fw\n",
    "\n",
    "# Catchment boundary masks for Antarctica, taken from ice shelf definitions in MPAS-Dev/geometric-features:\n",
    "# https://github.com/MPAS-Dev/geometric_features/tree/main/geometric_data\n",
    "# These have been combined into one file with 133 defined regions (polygons and multipolygons), \n",
    "# readable via the Geopandas package\n",
    "\n",
    "# Read geoJSON region feature file as a GeoDataFrame\n",
    "iceshelvesmask = gpd.read_file(inDirName + 'iceShelves.geojson')\n",
    "\n",
    "# Convert to south polar stereographic projection\n",
    "#icems = iceshelvesmask.to_crs({'init': 'epsg:3031'}); # This has been deprecated\n",
    "icems = iceshelvesmask.to_crs('epsg:3031');\n",
    "crs = ccrs.SouthPolarStereo();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c74213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boundaries\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "ax1 = plt.subplot(121,projection=ccrs.SouthPolarStereo())\n",
    "#ax1.gridlines(color='whitesmoke',zorder=4)\n",
    "icems[34:133].plot(ax=ax1,color='antiquewhite', linewidth=0,zorder=1)\n",
    "ax1.patch.set_facecolor(color='lightsteelblue')\n",
    "#ax1.add_feature(cartopy.feature.LAND, color='ghostwhite')\n",
    "ax1.add_feature(cartopy.feature.LAND, color='ghostwhite', zorder=2)\n",
    "plt.title('Catchment Boundaries');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4a2e1",
   "metadata": {},
   "source": [
    "### Sample data for specific ice shelves (time averaged melt rate draft dependence)\n",
    "\n",
    "Scatterplot of Antarctic catchments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure: Melt rate draft dependence for select catchments\n",
    "# The following indices are taken from 'catchment_scatter', defined as\n",
    "# Index of catchments in catchment_scatter = Index of catchments in icems - 33\n",
    "\n",
    "# Sample ice shelves chosen:\n",
    "# Amery = 1\n",
    "# George VI = 27\n",
    "# Getz = 28\n",
    "# Pine Island = 61\n",
    "# Ronne = 70\n",
    "# Totten = 83\n",
    "# Wilkins = 94\n",
    "# Western Ross = 71\n",
    "# Filchner = 22\n",
    "# Thwaites = 81\n",
    "# Eastern_Ross = 72\n",
    "\n",
    "# Full list of ice shelves and indices can be obtained by printing icems\n",
    "\n",
    "#catchments = np.array([1,27,28,61,70,83,94,71,22])\n",
    "\n",
    "catchments = np.array([1,27,28,61,70,83])\n",
    "basins=catchments+33\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "#fig, ax = plt.subplots(1, 1, figsize=[15, 15],subplot_kw={'projection': ccrs.SouthPolarStereo()})\n",
    "fig, axs = plt.subplots(2,3, figsize=[15, 10])\n",
    "axs=axs.ravel()\n",
    "\n",
    "for i,label in enumerate(('(a)', '(b)', '(c)', '(d)', '(e)', '(f)')):\n",
    "    axs[i].scatter(catchments_scatter[catchments[i]],ssh[1],color='r',s=1)\n",
    "    #axs[i].set_xlabel('Melt Flux (kg / m2 / s)')\n",
    "    #axs[i].set_ylabel('Depth (m)')\n",
    "    axs[i].set_ylim(-1000,0) # Specified for consistency across plots, some catchments are not as deep as others\n",
    "    # Uncomment to set xlim values for easy comparison of forcing magnitudes (varies across ice shelves)\n",
    "    #axs[i].set_xlim(-0.5e-6,2e-5)\n",
    "    axs[i].set_title('{}'.format(icems.name[33+catchments[i]]))\n",
    "    axs[i].text(-0.04, 1.08, label, transform=axs[i].transAxes ,fontweight='bold', va='top')\n",
    "    # axs[i].inset_axes([], projection=crs) does not seem to work, hence the workaround below:\n",
    "    # Refer here: https://github.com/matplotlib/matplotlib/pull/22608 for future revisions\n",
    "    axins = inset_axes(axs[i],width=\"30%\", height=\"30%\", loc=\"upper right\", \n",
    "                       axes_class=cartopy.mpl.geoaxes.GeoAxes, \n",
    "                       axes_kwargs=dict(projection=ccrs.SouthPolarStereo()))\n",
    "    icems[33:133].plot(ax=axins,linewidth=0.3,color='lightsteelblue')\n",
    "    axins.coastlines(resolution='10m',linewidth=0.25)\n",
    "    icems.loc[[33+catchments[i]],'geometry'].plot(ax=axins,color='r',linewidth=0.4)\n",
    "    #axs[i].set_axis_off();\n",
    "    axins.set_axis_off();\n",
    "    axs[i].grid(alpha=0.5)\n",
    "\n",
    "axs[0].set_ylabel('Depth (m)');\n",
    "axs[3].set_ylabel('Depth (m)');\n",
    "\n",
    "axs[3].set_xlabel('Melt Rate ($m/yr$)');\n",
    "axs[4].set_xlabel('Melt Rate ($m/yr$)');\n",
    "axs[5].set_xlabel('Melt Rate ($m/yr$)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d52bf",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "For time series plots and comparisons, the sum of flux across the spatial domain (or specific ice shelves) is used as a proxy when required. The mean can also be used here, without any loss of information, as the idea is only to compare trendlines.\n",
    "\n",
    "However, this might not be possible once the data is normalized, as the magnitude of data is removed at that stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae42d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demean: remove temporal mean\n",
    "# A pre-processed (\"dedrafted\") dataset is provided with this code. \n",
    "# In case of a linear regression, the xarray.polyfit or xarrayutils functions can be used:\n",
    "# https://docs.xarray.dev/en/stable/generated/xarray.Dataset.polyfit.html\n",
    "# https://xarrayutils.readthedocs.io/en/latest/utils.html\n",
    "\n",
    "flux_dedraft_tmean = flux_dedraft.mean('time')\n",
    "flux_dedraft_demeaned = flux_dedraft - flux_dedraft_tmean\n",
    "\n",
    "# Deseasonalize\n",
    "# Remove climatologies to isolate anomalies / deseasonalize \n",
    "flux_month = flux_dedraft_demeaned.groupby(\"time.month\")\n",
    "flux_clm = flux_month.mean(\"time\") # Climatologies\n",
    "flux_anm = flux_month - flux_clm # Deseasonalized anomalies\n",
    "\n",
    "# Remove initial 'model spinup period' data before analysis\n",
    "spinup_period_years = 25 # Verify period of datapoints to be removed before PCA\n",
    "spinup_time_period = 12*spinup_period_years\n",
    "#flux_clean = flux_anm[spinup_time_period:]\n",
    "\n",
    "flux_seasonal = (flux_dedraft - flux_anm)*sec_per_year/rho_fw\n",
    "flux_drft = (flux - flux_dedraft)*sec_per_year/rho_fw\n",
    "\n",
    "flux_seasonal = flux_seasonal[spinup_time_period:]\n",
    "flux_drft = flux_drft[spinup_time_period:]\n",
    "\n",
    "# Normalize \n",
    "flux_clean_tmean = flux_clean.mean('time')\n",
    "flux_clean_tstd = flux_clean.std('time')\n",
    "flux_clean_demeaned = flux_clean - flux_clean_tmean\n",
    "flux_clean_normalized = flux_clean_demeaned/flux_clean_tstd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a22324",
   "metadata": {},
   "source": [
    "## EOF/PCA Decomposition\n",
    "\n",
    "EOF decomposition in this version is done using a forked version of the `xeofs` package.\n",
    "Refer [nicrie/xeofs](https://github.com/nicrie/xeofs) on Github for documentation. The forked version, important for reconstructing datasets using the randomized PCs and for using PCA alternatives can be found here: [mshiv/xeofs-rand](https://github.com/mshiv/xeofs-rand). Alternate solvers (PCA, SparsePCA, TruncatedSVD etc. have been implemented as methods, but can also directly be called using the `scikit-learn` package.\n",
    "\n",
    "See [scikit-learn.decomposition](https://scikit-learn.org/stable/modules/decomposition.html#decompositions) user guide for more on usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e75a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Non-normalized variability decomposition \n",
    "model = EOF(flux_clean)\n",
    "model.solve()\n",
    "eofs = model.eofs()\n",
    "pcs = model.pcs()\n",
    "nmodes = model.n_modes\n",
    "varexpl = model.explained_variance_ratio()\n",
    "pcs_eig = model.pcs(1)\n",
    "\n",
    "# Normalized variability decomposition \n",
    "norm_model = EOF(flux_clean_normalized)\n",
    "norm_model.solve()\n",
    "norm_eofs = norm_model.eofs()\n",
    "norm_pcs = norm_model.pcs()\n",
    "norm_nmodes = norm_model.n_modes\n",
    "norm_varexpl = norm_model.explained_variance_ratio()\n",
    "norm_pcs_eig = norm_model.pcs(1)\n",
    "norm_eofs_eig = norm_model.eofs(1)\n",
    "norm_eofs_sng = norm_model.eofs(2)\n",
    "norm_pcs_sng = norm_model.pcs(2)\n",
    "norm_varexpl_values = norm_model.explained_variance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b93942",
   "metadata": {},
   "source": [
    "### Relative power of eigenmodes and dominant eigenmodes\n",
    "\n",
    "* Model output variability data (`flux_clean`)\n",
    "* Normalized model output variability data (`flux_clean_normalized`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative variance captured\n",
    "Fv_cs = varexpl.cumsum()\n",
    "Fvn_cs = norm_varexpl.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e1d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot figure\n",
    "# Figure: EOF modes from decomposition of normalized model variability data\n",
    "\n",
    "nmodes_plot = 3 # Number of modes to plot\n",
    "\n",
    "yr_length = range(0,125)\n",
    "yrs_plot = np.repeat(yr_length, 12)\n",
    "\n",
    "#sns.set_theme()\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig=plt.figure(figsize=(12,8))\n",
    "gs = GridSpec(nmodes_plot,2,width_ratios=[1.5,2])\n",
    "axbig = fig.add_subplot(gs[0,:])\n",
    "ax0 = [fig.add_subplot(gs[i,0],projection=crs) for i in range(1,nmodes_plot)]\n",
    "ax1 = [fig.add_subplot(gs[i,1]) for i in range(1,nmodes_plot)]\n",
    "\n",
    "for i, (a0, a1) in enumerate(zip(ax0, ax1)):\n",
    "    norm_eofs_eig.sel(mode=i+1).plot(ax=a0,\n",
    "                            cmap='cmo.balance',\n",
    "                            add_colorbar=True,\n",
    "                            cbar_kwargs={'orientation': 'vertical',\n",
    "                                         'label': 'SD Units'})\n",
    "    a0.coastlines(resolution='10m',linewidth=0.25,color='0.8')\n",
    "    a0.set_title('EOF Mode {}'.format(i+1))\n",
    "    a1.set_ylim(-3,3)\n",
    "    a1.plot(norm_pcs_eig.sel(mode=i+1),linewidth=1,color='dimgray')\n",
    "    a1.set_xlabel('')\n",
    "    a1.set_title('PC Mode {}'.format(i+1))\n",
    "    a1.tick_params(labelbottom=False, left=False, grid_alpha=0.3)\n",
    "\n",
    "a1.set_xlabel('Time (months)');\n",
    "\n",
    "m = 500\n",
    "xvar = np.linspace(1,m,m)\n",
    "axbig.plot(xvar,Fv_cs[:m]*100, 'k*--', lw=0.5,markersize=1.75,\n",
    "         label='Actual Data: {:.2f}\\%'.format(F_v_varexpl[:m].sum().values*100))\n",
    "axbig.plot(xvar,Fvn_cs[:m]*100, 'rh--', lw=0.5,markersize=0.75,\n",
    "         label='Normalized Data: {:.2f}\\%'.format(F_vn_varexpl[:m].sum().values*100))\n",
    "axbig.set_ylabel('Cumulative variance captured (\\%)')\n",
    "axbig.set_xlabel('Mode Number')\n",
    "axbig.set_title('Cumulative variance captured by first {} modes'.format(m));\n",
    "axbig.tick_params(labelbottom=True, left=False, grid_alpha=0.3)\n",
    "axbig.legend();\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7022dcc",
   "metadata": {},
   "source": [
    "## Fourier Phase Randomization\n",
    "\n",
    "Now, the projection co-efficients from the previous step are phase-randomized to generate new realizations of the data. In this step, we sample phases for each FFT(PC) from (0,$2\\pi$), and iterate to generate n realizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##############################\n",
    "# FOURIER PHASE RANDOMIZATION \n",
    "##############################\n",
    "\n",
    "# Define number of random Fourier realizations\n",
    "n_realizations = 5\n",
    "t_length = norm_pcs.shape[0]\n",
    "\n",
    "# Define random number generator \n",
    "#rng = np.random.default_rng(2021)\n",
    "#random_phases = np.exp(np.random.default_rng(2023).uniform(0,2*np.pi,int(len(fl)/2+1))*1.0j) in line 26\n",
    "\n",
    "# xeofs_pcs[:,i] when using PCA outputs\n",
    "new_fl = np.empty((n_realizations,norm_pcs.shape[0],norm_pcs.shape[1]))\n",
    "\n",
    "# Time limits for plotting\n",
    "t1 = 0\n",
    "tf = int(t_length/2)\n",
    "\n",
    "for i in range(n_realizations):\n",
    "    for m in range(nmodes):\n",
    "        fl = norm_pcs[:,m] # fluxpcs[:,i] when using PCA outputs\n",
    "        fl_fourier = np.fft.rfft(fl)\n",
    "        random_phases = np.exp(np.random.uniform(0,2*np.pi,int(len(fl)/2+1))*1.0j)\n",
    "        fl_fourier_new = fl_fourier*random_phases\n",
    "        new_fl[i,:,m] = np.fft.irfft(fl_fourier_new)\n",
    "    print('calculated ifft for realization {}, all modes'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ce634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plot of generated PCs\n",
    "\n",
    "nmodes_plot = 4 # Number of modes to plot\n",
    "nrealizations_to_plot = 5 # to be lesser than absolute total number, defined in the Fourier randomization step\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "fig=plt.figure(figsize=(25,20))\n",
    "\n",
    "gs = GridSpec(nmodes_plot, 2, width_ratios=[4, 2])\n",
    "ax0 = [fig.add_subplot(gs[i, 0]) for i in range(nmodes_plot)]\n",
    "ax1 = [fig.add_subplot(gs[i, 1]) for i in range(nmodes_plot)]\n",
    "\n",
    "for i, (a0,a1) in enumerate(zip(ax0,ax1)):\n",
    "    for n_realization in range(0,nrealizations_to_plot):\n",
    "        a0.plot(new_fl[n_realization,:,i],color='b', linewidth=0.5)\n",
    "        a1.psd(new_fl[n_realization,:,i],color='b', linewidth=0.5)\n",
    "    a0.plot(new_fl[0,:,i],color='b', linewidth=0.25,label='Randomized')\n",
    "    a1.psd(new_fl[0,:,i],color='b', linewidth=0.25,label='Randomized')\n",
    "    a0.plot(pcs[:,i],color='k', linewidth=2.5,label='Original')\n",
    "    a1.psd(pcs[:,i],color='k', linewidth=2.5,label='Original')\n",
    "    a0.set_title('PC for EOF mode {}'.format(i+1))\n",
    "    a1.set_title('PSD for PC mode {}'.format(i+1))\n",
    "    a1.set_xlabel('')\n",
    "\n",
    "a0.set_xlabel('Time (months)')\n",
    "a1.set_xlabel('Frequency')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb0cb3",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "Functions defined for the generation and follow on calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified to not return f - in calculation of RMSE, only Px required\n",
    "def psd_calc_grid(data,y,x):\n",
    "    f, Px = scipy.signal.welch(data[:,y,x])\n",
    "    return Px\n",
    "\n",
    "def time_series(clipped_data):\n",
    "    clipped_ts = clipped_data.sum(['y','x'])\n",
    "    return clipped_ts\n",
    "\n",
    "# Reconstruct flux dataset using phase randomized PCs\n",
    "# This section is to be called iteratively for ensemble runs with multiple realizations\n",
    "# This method also takes 'modes' as a parameter: \n",
    "# which is used to reconstruct dataset with different number of selected modes\n",
    "\n",
    "def generate_data(n_realization,mode,mode_skip):\n",
    "    # mode can be any int in (1,nmodes), for cases \n",
    "    # when dimensionality reduction is preferred on the reconstructed dataset\n",
    "    flux_reconstr = norm_model.reconstruct_randomized_X(new_fl[n_realization],slice(1,mode,mode_skip))\n",
    "    #flux_reconstr = flux_reconstr.dropna('time',how='all')\n",
    "    #flux_reconstr = flux_reconstr.dropna('y',how='all')\n",
    "    #flux_reconstr = flux_reconstr.dropna('x',how='all')\n",
    "    #flux_reconstr = flux_reconstr.drop(\"month\")\n",
    "    return flux_reconstr\n",
    "\n",
    "def clip_data(total_data, basin):\n",
    "    clipped_data = total_data.rio.clip(icems.loc[[basin],'geometry'].apply(mapping))\n",
    "    #clipped_data = clipped_data.dropna('time',how='all')\n",
    "    #clipped_data = clipped_data.dropna('y',how='all')\n",
    "    #clipped_data = clipped_data.dropna('x',how='all')\n",
    "    clipped_data = clipped_data.drop(\"month\")\n",
    "    return clipped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a885152",
   "metadata": {},
   "source": [
    "### Statistical Generation\n",
    "\n",
    "This step uses functions committed to the `xeofs-rand` fork. *Ref: For commit diff details, see [mshiv/xeofs-rand](https://github.com/nicrie/xeofs/compare/main...mshiv:xeofs-rand:main).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134839a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset realizations\n",
    "\n",
    "## Standard EOF/PCA implementation\n",
    "# Can use the xeofs-rand package, or directly generate using sklearn PCA.\n",
    "\n",
    "for i in range(n_realizations):\n",
    "    flux_reconstr = generate_data(i, 1500, 1)\n",
    "    flux_reconstr = (flux_reconstr*flux_clean_tstd)+flux_clean_tmean\n",
    "    melt_reconstr = flux_reconstr*sec_per_year/rho_fw\n",
    "    melt_reconstr = melt_reconstr.rename('rec{}'.format(n_realizations))\n",
    "    melt_reconstr.to_netcdf(inDirName+\"REC{}.nc\".format(i))\n",
    "    print('reconstructed realization # {}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e912b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input generated dataset files\n",
    "# This section presents a sample case of 1 generated realization\n",
    "# Customize this section as necessary\n",
    "rec0 = xr.open_dataset(inDirName+\"REC0.nc\").rec0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0c37ac",
   "metadata": {},
   "source": [
    "### Sparse PCA Implementation\n",
    "\n",
    "[`sklearn.decomposition.SparsePCA`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparsePCA.html) was added to the `xeofs-rand` fork as a method.\n",
    "\n",
    "`MiniBatchSparsePCA` can be used instead to improve computational speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56106d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# SPARSE DECOMPOSITION \n",
    "##############################\n",
    "\n",
    "norm_model.solvesparse()\n",
    "spca_eofs = model.eofs()\n",
    "spca_pcs = model.pcs()\n",
    "\n",
    "##############################\n",
    "# FOURIER PHASE RANDOMIZATION \n",
    "##############################\n",
    "\n",
    "# Define number of random Fourier realizations\n",
    "n_realizations = 3\n",
    "t_length = pcs.shape[0]\n",
    "\n",
    "# Define random number generator \n",
    "#rng = np.random.default_rng(2021)\n",
    "#random_phases = np.exp(np.random.default_rng(2023).uniform(0,2*np.pi,int(len(fl)/2+1))*1.0j) in line 26\n",
    "\n",
    "# xeofs_pcs[:,i] when using PCA outputs\n",
    "new_fl = np.empty((n_realizations,pcs.shape[0],pcs.shape[1]))\n",
    "\n",
    "# Time limits for plotting\n",
    "t1 = 0\n",
    "tf = int(t_length/2)\n",
    "\n",
    "for i in range(n_realizations):\n",
    "    for m in range(nmodes):\n",
    "        fl = pcs[:,m] # fluxpcs[:,i] when using PCA outputs\n",
    "        fl_fourier = np.fft.rfft(fl)\n",
    "        #random_phases = np.exp(np.random.uniform(0,2*np.pi,int(len(fl)/2+1))*1.0j)\n",
    "        #random_phases = np.exp(np.random.default_rng(2023).uniform(0,2*np.pi,int(len(fl)/2+1))*1.0j)\n",
    "        random_phases = np.exp(np.random.uniform(0,2*np.pi,int(len(fl)/2+1))*1.0j)\n",
    "        fl_fourier_new = fl_fourier*random_phases\n",
    "        new_fl[i,:,m] = np.fft.irfft(fl_fourier_new)\n",
    "    print('calculated ifft for realization {}, all modes'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b04c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_realizations):\n",
    "    new_fl_xr = xr.DataArray(new_fl[i], dims=pcs.dims, coords = pcs.coords, attrs = pcs.attrs)\n",
    "    sparse_mini_rand = new_fl_xr @ spca_eofs.T\n",
    "    # Imperative to check the above generated dataset for consistent dimensions\n",
    "    sparse_mini_rand = sparse_mini_rand.transpose(\"time\",\"y\",\"x\")\n",
    "    sparse_mini_rand = (sparse_mini_rand*flux_clean_tstd)+flux_clean_tmean\n",
    "    melt_spca_reconstr = sparse_mini_rand*sec_per_year/rho_fw\n",
    "    melt_spca_reconstr = melt_spca_reconstr.rename('spcarec{}'.format(n_realizations))\n",
    "    sparse_mini_rand.to_netcdf(inDirName+\"spcaREC{}.nc\".format(i))\n",
    "    print(\"Created randomized realization...{}\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input generated dataset files\n",
    "# This section presents a sample case of 1 generated realization\n",
    "# Customize this section as necessary\n",
    "spcarec0 = xr.open_dataset(inDirName+\"spcaREC0.nc\").spcarec0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f3c79",
   "metadata": {},
   "source": [
    "### Generator variability output \n",
    "\n",
    "For full AIS, and select basins: time series at a grid point and power spectral densities for the full ice shelf are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc3c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#catchments = np.array([1,27,28,61,70,83,94,71,22])\n",
    "#basins = catchments+33\n",
    "\n",
    "#basins = [34, 55, 60, 61, 94, 103]\n",
    "#basins = [55,94]\n",
    "#basins = [34, 60]\n",
    "#grid_points = np.array(([85,105], [115,45], [4,45],[21,56], [11,10], [34,95]))\n",
    "#grid_points = np.array(([115,45],[11,10]))\n",
    "#grid_points = np.array(([85,105],[4,45]))\n",
    "\n",
    "basins = [34,94,60,55,94]\n",
    "# Choose grid points based on dataset indices. Can find these using data.x and data.y dimension arrays.\n",
    "# Locations here have been selected based on performance of model simulation data at these points, \n",
    "# given also the variance between them (in terms of temporal scale of variability)\n",
    "grid_points = np.array(([85,105], [11,10],[15,44], [100,40]))\n",
    "\n",
    "#basins = np.array([34, 60, 94, 55])\n",
    "# [2,3,4,5] = [Antarctica, Peninsula, West Antarctica, East Antarctica]\n",
    "\n",
    "n_basins = len(basins)\n",
    "oc = 'k'\n",
    "pcac = '#D55E00'#'#FC8D62'\n",
    "spcac = 'steelblue'#'#0072B2' #'#CC79A7'\n",
    "\n",
    "lwbg = 0.1\n",
    "lworig = 1.5\n",
    "lwgen = 0.8\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "fig=plt.figure(figsize=(18,4*n_basins))\n",
    "gs = GridSpec(n_basins, 2, width_ratios=[1,3])\n",
    "axtop = fig.add_subplot(gs[0, :])\n",
    "ax0 = [fig.add_subplot(gs[i, 0]) for i in range(1,n_basins)]\n",
    "ax1 = [fig.add_subplot(gs[i, 1]) for i in range(1,n_basins)]\n",
    "\n",
    "for i,(a0,a1,grids) in enumerate(zip(ax0,ax1,grid_points)):\n",
    "    orig = clip_data(flux_clean, basins[i])\n",
    "    gen0 = clip_data(rec0, basins[i])\n",
    "    spcagen0 = clip_data(spcarec0, basins[i])\n",
    "    combined = xr.merge([orig,gen0,spcagen0])\n",
    "    combined_ts = time_series(combined)\n",
    "    a1.plot(orig[:,grids[0],grids[1]],color=oc, linewidth=lworig,label='Model Data ($F_v$)')\n",
    "    a1.plot(spcagen0[:,grids[0],grids[1]],color=spcac, linewidth=lwgen,label='Sparse PCA Gen. Data ($F\\'_v$)')\n",
    "    a1.plot(gen0[:,grids[0],grids[1]],color=pcac, linewidth=lwgen, label='PCA Gen. Data ($F\\'_v$)')\n",
    "    axin1 = inset_axes(a1, width=\"30%\", height=\"30%\", loc=\"upper right\", \n",
    "                       axes_class=cartopy.mpl.geoaxes.GeoAxes, \n",
    "                       bbox_to_anchor=(0.07,-0.025,1,1),bbox_transform=a1.transAxes,\n",
    "                       axes_kwargs=dict(projection=ccrs.SouthPolarStereo()))\n",
    "    axin1.coastlines(resolution='10m',linewidth=0.25)\n",
    "    axin1.add_feature(cartopy.feature.LAND, color='#B3B3B3',zorder=2,alpha=0.5)\n",
    "    icems.loc[[basins[i]],'geometry'].plot(ax=axin1,color='#B3B3B3',linewidth=0.4,alpha=0.75,zorder=3)\n",
    "    axin1.coastlines(resolution='10m',linewidth=0.25,zorder=4)\n",
    "    axin1.plot(orig.x[grids[1]],orig.y[grids[0]],marker='*',color='k',zorder=4)\n",
    "    a1.set_title('Sample melt rate variability in the {} catchment'.format(icems.name[basins[i]]))\n",
    "    a1.set_ylabel('Melt Rate ($m/yr$)');\n",
    "    a1.set_xlabel('')\n",
    "    a1.tick_params(labelbottom=False)\n",
    "    a1.legend(loc=\"lower right\");\n",
    "    a1.grid(color='dimgray', linestyle='-', linewidth=0.25)\n",
    "    a0.psd(combined_ts.spcagen0,color=spcac, linewidth=lwgen)\n",
    "    a0.psd(combined_ts.gen0,color=pcac, linewidth=lwgen)\n",
    "    a0.psd(combined_ts.orig,color=oc, linewidth=lworig)    \n",
    "    axin0 = inset_axes(a0, width=\"30%\", height=\"30%\", loc=\"upper right\", \n",
    "                       axes_class=cartopy.mpl.geoaxes.GeoAxes, \n",
    "                       bbox_to_anchor=(-0.99,-0.025,1,1),bbox_transform=a1.transAxes,\n",
    "                       axes_kwargs=dict(projection=ccrs.SouthPolarStereo()))\n",
    "    icems[33:133].plot(ax=axin0,linewidth=0.3,color='#B3B3B3')\n",
    "    axin0.coastlines(resolution='10m',linewidth=0.15)\n",
    "    icems.loc[[basins[i]],'geometry'].plot(ax=axin0,color='k',linewidth=0.4, label=\"Selected Grid Point\")\n",
    "    a0.set_title('Full ice shelf PSD: {}'.format(icems.name[basins[i]]))\n",
    "    a0.tick_params(labelbottom=False)\n",
    "    a0.set_xlabel('')\n",
    "    del orig, gen0, spcagen0, combined, combined_ts\n",
    "a1.set_xlabel('Time (months)');\n",
    "a0.set_xlabel('Frequency');\n",
    "\n",
    "# Full AIS power spectral density plots\n",
    "axtop.psd(time_series(flux_clean), color = oc, lw=lworig,label='Model Data ($F_v$)');\n",
    "axtop.psd(time_series(rec0), color= pcac, lw=lwgen, label='PCA Gen. Data ($F\\'_v$)');\n",
    "axtop.psd(time_series(spcarec0), color= spcac, lw=lwgen,label='Sparse PCA Gen. Data ($F\\'_v$)');\n",
    "axintop = inset_axes(axtop, width=\"30%\", height=\"30%\", loc=\"upper right\", \n",
    "                     bbox_to_anchor=(0.1,-0.025,1,1),bbox_transform=axtop.transAxes,\n",
    "                     axes_class=cartopy.mpl.geoaxes.GeoAxes, \n",
    "                     axes_kwargs=dict(projection=ccrs.SouthPolarStereo()))\n",
    "icems[2:3].plot(ax=axintop,linewidth=0.3,color='k',alpha=1)\n",
    "axintop.coastlines(resolution='10m',linewidth=0.15,color='white',zorder=5)\n",
    "axtop.set_title('Full AIS domain PSD Comparisons');\n",
    "axtop.legend(loc=\"lower right\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7c3dbe",
   "metadata": {},
   "source": [
    "## Generator output with all components added\n",
    "\n",
    "Generator output for a select few grid points in final output, with all components added back (Seasonality+draft dependence)\n",
    "\n",
    "Use the following grid points to plot time series of original data and generated data. Grid point indices are specified for clipped subdomains. (Use `clip_data(data, basin_number)` and use the specified indices on the output).\n",
    "\n",
    "Locations:\n",
    "1. Amery (basin = 34) : `(y=85,x=105)`\n",
    "2. George VI (basin = 60): `(y=4,x=45)`\n",
    "3. Getz (basin = 61): `(y=21,x=58)`\n",
    "4. Ronne (basin = 103): `(y=95,x=34)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d280decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See notebook 06-sm-... for methods to obtain original dataset, \n",
    "# seasonality calculations and dedrafting datafile locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bfee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all datasets are in terms of melt rate [m/yr], not freshwater flux\n",
    "F = flux*sec_per_year/rho_fw\n",
    "Frec = rec0 + flux_seasonal + flux_drft\n",
    "Fspcarec = spcarec0 + flux_seasonal + flux_drft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL DATA\n",
    "#orig = clip_data(flux, basin)\n",
    "#basins = [34, 60, 61, 103]\n",
    "#grid_points = np.array([[85,105],[4,45],[21,56],[95,34]])\n",
    "\n",
    "basins = [34,94]\n",
    "#grid_points = np.array(([85,105], [11,10],[15,44], [100,40]))\n",
    "grid_points = np.array(([85,105], [11,10]))\n",
    "\n",
    "basins = [34,94,60,55]\n",
    "#grid_points = np.array(([85,105], [11,10],[15,44], [100,40]))\n",
    "grid_points = np.array(([85,105], [11,10],[12,41], [100,40]))\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "fig, axs = plt.subplots(4,1, figsize=[20, 20])\n",
    "axs=axs.ravel()\n",
    "\n",
    "pltlabels = ['(a)','(b)','(c)','(d)']\n",
    "\n",
    "#n_basins = len(basins)\n",
    "color_orig = 'k'\n",
    "color_gen = 'dimgray'\n",
    "\n",
    "for i, grids in enumerate(zip(grid_points)):\n",
    "    #ssnl = clip_data(flux_seasonal, basins[i])\n",
    "    #drft = clip_data(flux_drft, basins[i])\n",
    "    orig = clip_data(F, basins[i])\n",
    "    spcarec = clip_data(Fspcarec, basins[i])\n",
    "    axs[i].plot(orig[:,grids[0][0],grids[0][1]],color=oc, linewidth=lworig,label='Model Data ($F_{orig}$)')\n",
    "    axs[i].plot(spcarec[:,grids[0][0],grids[0][1]],color=spcac, linewidth=lwgen,label='Sparse PCA Gen. Data ($F\\'_{gen}$)')\n",
    "    axs[i].set_title('Sample melt rate in the {} catchment'.format(icems.name[basins[i]]))\n",
    "    axins = inset_axes(axs[i], width=\"30%\", height=\"30%\", loc=\"upper right\", \n",
    "                       axes_class=cartopy.mpl.geoaxes.GeoAxes, \n",
    "                       bbox_to_anchor=(0.1,-0.025,1,1),bbox_transform=axs[i].transAxes,\n",
    "                       axes_kwargs=dict(projection=ccrs.SouthPolarStereo()))\n",
    "    axins.add_feature(cartopy.feature.LAND, color='#B3B3B3',zorder=2,alpha=0.5)\n",
    "    icems.loc[[basins[i]],'geometry'].plot(ax=axins,color='#B3B3B3', linewidth=0.45,zorder=3)\n",
    "    axins.coastlines(resolution='10m',linewidth=0.25,zorder=4)\n",
    "    axins.plot(orig.x[grids[0][1]],orig.y[grids[0][0]], marker='*', color='k',zorder=4)\n",
    "    axs[i].set_ylabel('Melt Rate ($m/yr$)');\n",
    "    axs[i].set_xlabel('');\n",
    "    axs[i].legend(loc=\"lower right\");\n",
    "    axs[i].grid(color='dimgray', linestyle='-', linewidth=0.2)\n",
    "    del rec01, rec1, rec3a\n",
    "\n",
    "axs[3].set_xlabel('Time (months)');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
